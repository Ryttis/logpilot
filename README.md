Perfect ğŸ‘ â€” hereâ€™s the entire content of your final README.md (plain text, ready to copy & paste directly).
You can select everything below and paste it into your /logpilot/README.md file â€” it will render correctly on GitHub.

## ğŸ§  LogPilot â€” Real-Time Nginx Log Analytics

LogPilot is a lightweight full-stack system for collecting, parsing, and analyzing Nginx access logs.
It combines Node.js + Express + MySQL + Sequelize on the backend with a Vite + Alpine.js + TailwindCSS dashboard frontend.

## ğŸš€ Features

Stream-based Nginx log parser (handles 1M+ lines efficiently)

Automatic route hashing + mapping for secure storage

Worker/Scheduler scans and ingests logs periodically

REST API for logs and statistics:

/api/logs â€“ list logs

/api/logs/:ip â€“ logs by IP

/api/logs/stats â€“ aggregated hits by IP & route

Frontend dashboard with:

Real-time chart of top IPs

Refreshable table of routes & hits

Configurable log directory via .env

One-command dev environment (npm run up)

Production-ready build served from client/dist

## ğŸ—ï¸ System Architecture

Alpine.js (Vite + Tailwind + Chart.js)
â†“ REST API
Express backend (Node.js + Sequelize)
â†“
MySQL database (nginx_logs, route_map)
â†“
Worker Scheduler (node-cron)

âš™ï¸ How It Works

Scheduler runs every 5 minutes â†’ scans the folder defined in LOG_DIR for new or updated .log files.

LogParserService reads each line, extracts fields, hashes the route, encodes the payload, and saves it.

API provides access endpoints to retrieve or aggregate stored logs.

Frontend dashboard fetches /api/logs/stats, displays charts and tables, and auto-refreshes every 30s.

## ğŸ§© Tech Stack

Backend: Node.js Â· Express Â· Sequelize
Database: MySQL
Frontend: Vite Â· Alpine.js Â· TailwindCSS Â· Chart.js
Scheduler: node-cron
Utilities: dotenv Â· concurrently Â· nodemon

## ğŸ› ï¸ Installation (Development)

1ï¸âƒ£ Clone the repository:

git clone https://github.com/yourname/logpilot.git
cd logpilot


2ï¸âƒ£ Install dependencies:

npm install
cd client && npm install && cd ..


3ï¸âƒ£ Create .env in the root:

LOG_DIR=./logs
PORT=3000
NODE_ENV=development
DB_USER=root
DB_PASS=yourpassword
DB_NAME=logpilot
DB_HOST=127.0.0.1

## ğŸ§° Running in Development

To start everything (backend + frontend + worker):

npm run up


Or individually:

npm run dev      # API only
npm run client   # frontend only (Vite)
npm run worker   # background ingestion


Access points:

API â†’ http://localhost:3000/api/logs

Frontend â†’ http://localhost:5173

## ğŸ§± Building for Production

1ï¸âƒ£ Build frontend:

npm run build


2ï¸âƒ£ Run in production:

NODE_ENV=production npm start


Express will serve the built dashboard at http://localhost:3000

3ï¸âƒ£ Optionally run API + worker together:

npm run all

## ğŸ§© Database Setup

Apply migrations:

npm run migrate


Reset database:

npm run reset

ğŸ”„ Log Storage & Decoding

Logs are encoded (Base64) and linked by route_hash.

Table route_map stores hash â†’ readable route mapping.

API decodes and resolves routes before returning to frontend.

âš™ï¸ Environment Variables

LOG_DIR â€“ path to Nginx logs folder
PORT â€“ web server port
NODE_ENV â€“ environment (development/production)
DB_USER / DB_PASS / DB_NAME / DB_HOST â€“ MySQL connection settings

## ğŸ“¦ Folder Structure
logpilot/
â”œâ”€ src/
â”‚  â”œâ”€ app.js
â”‚  â”œâ”€ server.js
â”‚  â”œâ”€ controllers/
â”‚  â”œâ”€ services/
â”‚  â”œâ”€ workers/
â”œâ”€ models/
â”œâ”€ db/migrations/
â”œâ”€ client/
â”œâ”€ logs/
â””â”€ .env

## ğŸ§  Example Workflow

Copy your access.log files into ./logs/

Worker parses them automatically every 5 minutes

Data stored in MySQL (nginx_logs)

Dashboard visualizes routes and IP stats

ğŸš¢ Production Checklist

âœ… Build frontend â€“ npm run build
âœ… Set NODE_ENV=production
âœ… Start â€“ npm start or npm run all
âœ… Migrate DB â€“ npm run migrate
âœ… Configure .env (database + log path)


## ğŸ§‘â€ğŸ’» Example API Calls

List recent logs:

curl http://localhost:3000/api/logs?limit=10 | jq


Show statistics:

curl http://localhost:3000/api/logs/stats | jq

ğŸ’¡ Future Improvements

Incremental parsing (only new lines)

Multiple log sources

Role-based access/authentication

Docker Compose full-stack deployment

Ingestion performance metrics

ğŸ§¾ License

MIT License â€” free for personal or commercial use.